{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 187 models\n",
      "Skipping ./training-results/hp-tuning-s/2023-11-14 18:26:11.639586/episode=2_val-score=49.pt because results.yaml not found\n",
      "Found 186 models with okay results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>warm_start</th>\n",
       "      <th>replay_buffer_size</th>\n",
       "      <th>gamma</th>\n",
       "      <th>target_update_interval</th>\n",
       "      <th>ddqn</th>\n",
       "      <th>dueling_dqn</th>\n",
       "      <th>model_path</th>\n",
       "      <th>dir_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>97.6</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.218268</td>\n",
       "      <td>43</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>episode=1_val-score=100.pt</td>\n",
       "      <td>2023-11-13 18:31:39.499406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>94.8</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.992601</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>episode=4_val-score=95.pt</td>\n",
       "      <td>2023-11-13 21:38:47.405336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>94.6</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.650934</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>episode=1_val-score=96.pt</td>\n",
       "      <td>2023-11-13 16:01:51.568960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>94.2</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.492716</td>\n",
       "      <td>73</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>episode=3_val-score=95.pt</td>\n",
       "      <td>2023-11-14 15:21:23.042208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>94.2</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.817004</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>episode=3_val-score=98.pt</td>\n",
       "      <td>2023-11-13 20:10:57.478853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>93.8</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>0.924394</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>episode=13_val-score=97.pt</td>\n",
       "      <td>2023-11-14 02:47:54.735724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>93.0</td>\n",
       "      <td>256</td>\n",
       "      <td>2048</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.930493</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>episode=6_val-score=96.pt</td>\n",
       "      <td>2023-11-14 00:46:48.746845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>93.0</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.081510</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>episode=0_val-score=98.pt</td>\n",
       "      <td>2023-11-14 12:18:53.999387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>92.4</td>\n",
       "      <td>256</td>\n",
       "      <td>2048</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.507841</td>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>episode=8_val-score=96.pt</td>\n",
       "      <td>2023-11-13 16:40:40.392867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>91.2</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.478380</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>episode=9_val-score=92.pt</td>\n",
       "      <td>2023-11-14 07:36:39.216014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_score  batch_size  warm_start  replay_buffer_size     gamma  \\\n",
       "42         97.6         512        4096                8192  0.218268   \n",
       "182        94.8         256        1024                2048  0.992601   \n",
       "164        94.6         256         512                4096  0.650934   \n",
       "68         94.2         512        4096                8192  0.492716   \n",
       "87         94.2         512        1024                2048  0.817004   \n",
       "78         93.8         128         128                 512  0.924394   \n",
       "151        93.0         256        2048                8192  0.930493   \n",
       "10         93.0         256         256                2048  0.081510   \n",
       "55         92.4         256        2048               16384  0.507841   \n",
       "83         91.2         128         512                 512  0.478380   \n",
       "\n",
       "     target_update_interval   ddqn  dueling_dqn                  model_path  \\\n",
       "42                   43   True         True  episode=1_val-score=100.pt   \n",
       "182                  99  False        False   episode=4_val-score=95.pt   \n",
       "164                  19   True        False   episode=1_val-score=96.pt   \n",
       "68                   73   True        False   episode=3_val-score=95.pt   \n",
       "87                   71  False         True   episode=3_val-score=98.pt   \n",
       "78                   66  False         True  episode=13_val-score=97.pt   \n",
       "151                  65  False         True   episode=6_val-score=96.pt   \n",
       "10                   44  False         True   episode=0_val-score=98.pt   \n",
       "55                   49   True        False   episode=8_val-score=96.pt   \n",
       "83                   90   True        False   episode=9_val-score=92.pt   \n",
       "\n",
       "                       dir_name  \n",
       "42   2023-11-13 18:31:39.499406  \n",
       "182  2023-11-13 21:38:47.405336  \n",
       "164  2023-11-13 16:01:51.568960  \n",
       "68   2023-11-14 15:21:23.042208  \n",
       "87   2023-11-13 20:10:57.478853  \n",
       "78   2023-11-14 02:47:54.735724  \n",
       "151  2023-11-14 00:46:48.746845  \n",
       "10   2023-11-14 12:18:53.999387  \n",
       "55   2023-11-13 16:40:40.392867  \n",
       "83   2023-11-14 07:36:39.216014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from humemai.utils import read_yaml\n",
    "\n",
    "print(f\"Found {len(glob('./training-results/hp-tuning-s/*/*.pt'))} models\")\n",
    "table = []\n",
    "for model_path in glob(\"./training-results/hp-tuning-s/*/*.pt\"):\n",
    "    dir_name = os.path.dirname(model_path)\n",
    "    train_path = os.path.join(dir_name, \"train.yaml\")\n",
    "    results_path = os.path.join(dir_name, \"results.yaml\")\n",
    "\n",
    "    train = read_yaml(train_path)\n",
    "\n",
    "    # if \"episode=0\" in model_path or \"episode=1\" in model_path:\n",
    "    #     continue  # skip the weird ones\n",
    "\n",
    "    try:\n",
    "        results = read_yaml(results_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Skipping {model_path} because results.yaml not found\")\n",
    "        continue\n",
    "    table.append(\n",
    "        {\n",
    "            \"test_score\": results[\"test_score\"][\"mean\"],\n",
    "            \"batch_size\": train[\"batch_size\"],\n",
    "            \"warm_start\": train[\"warm_start\"],\n",
    "            \"replay_buffer_size\": train[\"replay_buffer_size\"],\n",
    "            \"gamma\": train[\"gamma\"],\n",
    "            \"target_update_interval\": train[\"target_update_interval\"],\n",
    "            \"ddqn\": train[\"ddqn\"],\n",
    "            \"dueling_dqn\": train[\"dueling_dqn\"],\n",
    "            \"model_path\": os.path.basename(model_path),\n",
    "            \"dir_name\": dir_name.split(\"/\")[-1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Found {len(table)} models with okay results\")\n",
    "\n",
    "df = pd.DataFrame(table)\n",
    "df = df.sort_values(\"test_score\", ascending=False)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    128\n",
       " Name: batch_size, dtype: int64,\n",
       " 0    1024\n",
       " Name: warm_start, dtype: int64,\n",
       " 0    4096\n",
       " Name: replay_buffer_size, dtype: int64,\n",
       " 0.5229346023350929,\n",
       " 67.20967741935483,\n",
       " 0    False\n",
       " Name: ddqn, dtype: bool,\n",
       " 0    False\n",
       " Name: dueling_dqn, dtype: bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.batch_size.mode(), df.warm_start.mode(), df.replay_buffer_size.mode(), df.gamma.mean(), df.target_update_interval.mean(), df.ddqn.mode(), df.dueling_dqn.mode()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7c14ce45c674ffbe7e3a8bc18299264a1035542c780d18c0e8f0c585e044f28"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dev-python3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
